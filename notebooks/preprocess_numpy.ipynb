{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filepath):\n",
    "    \"\"\"To be completed\"\"\"\n",
    "    \n",
    "    # Load the text\n",
    "    with open(filepath) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "        \n",
    "    # Remove punctuation for better performance\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    text = [w.translate(table) for w in text]\n",
    "    print(text[:100])\n",
    "    \n",
    "    # Create mapping of unique chars to integers\n",
    "    chars = sorted(list(set(text)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    print(chars)\n",
    "    \n",
    "    # Summarize the loaded data\n",
    "    n_chars = len(text)\n",
    "    n_vocab = len(chars)\n",
    "    print(f\"Total Characters:{n_chars}\")\n",
    "    print(f\"Total Vocab:{n_vocab}\")\n",
    "    \n",
    "    # Prepare the dataset of input to output pairs encoded as integers\n",
    "    seq_length = 100\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    \n",
    "    for i in range(0, n_chars - seq_length, 1):\n",
    "        seq_in = text[i:i + seq_length]\n",
    "        seq_out = text[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "        \n",
    "    n_patterns = len(dataX)\n",
    "    print(f\"Total Patterns:{n_patterns}\")\n",
    "    \n",
    "    # reshape X to be [samples, time steps, features]\n",
    "    X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "    \n",
    "    # normalize\n",
    "    X = X / float(n_vocab)\n",
    "    \n",
    "    # one hot encode the output variable\n",
    "    y = np_utils.to_categorical(dataY)   \n",
    "    \n",
    "    processed_X = np.save(\n",
    "        \"/home/tdelatte/Projects/Deep_Learning/NLP/Baudelaire_Poem_Generator/data/processed/processed_X.npy\", X)\n",
    "    processed_y = np.save(\n",
    "        \"/home/tdelatte/Projects/Deep_Learning/NLP/Baudelaire_Poem_Generator/data/processed/processed_y.npy\", y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['à', ' ', 'c', 'e', 'l', 'l', 'e', ' ', 'q', 'u', 'i', ' ', 'e', 's', 't', ' ', 't', 'r', 'o', 'p', ' ', 'g', 'a', 'i', 'e', '\\n', 't', 'a', ' ', 't', 'ê', 't', 'e', '', ' ', 't', 'o', 'n', ' ', 'g', 'e', 's', 't', 'e', '', ' ', 't', 'o', 'n', ' ', 'a', 'i', 'r', ' ', '\\n', 's', 'o', 'n', 't', ' ', 'b', 'e', 'a', 'u', 'x', ' ', 'c', 'o', 'm', 'm', 'e', ' ', 'u', 'n', ' ', 'b', 'e', 'a', 'u', ' ', 'p', 'a', 'y', 's', 'a', 'g', 'e', ' ', '', ' ', '\\n', 'l', 'e', ' ', 'r', 'i', 'r', 'e', ' ', 'j']\n",
      "['', '\\n', ' ', '0', '1', '2', '3', '4', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '«', '»', 'à', 'â', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'ü', 'œ', '—']\n",
      "Total Characters:235437\n",
      "Total Vocab:56\n",
      "Total Patterns:235337\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess(\"/home/tdelatte/Projects/Deep_Learning/NLP/Baudelaire_Poem_Generator/data/raw/baudelaire.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
